{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "If you have a word file than a pdf , here is the code to convert word to pdf"
      ],
      "metadata": {
        "id": "atX-P-aMBg6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Function to convert Word to PDF\n",
        "def convert_word_to_pdf(word_file_path, pdf_file_path):\n",
        "\n",
        "    doc = Document(word_file_path)\n",
        "\n",
        "    pdf = FPDF()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    for paragraph in doc.paragraphs:\n",
        "        pdf.multi_cell(0, 10, paragraph.text)\n",
        "\n",
        "    pdf.output(pdf_file_path)\n",
        "    print(f\"PDF saved to {pdf_file_path}\")\n",
        "\n",
        "word_file_path = '/content/your_word_file.docx'\n",
        "pdf_file_path = '/content/your_output_file.pdf'\n",
        "\n",
        "convert_word_to_pdf(word_file_path, pdf_file_path)\n"
      ],
      "metadata": {
        "id": "J0GGuiSNBTvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "from google.colab import files\n",
        "files.download(pdf_file_path)"
      ],
      "metadata": {
        "id": "elLBAIXOBdFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "imports and external downloads"
      ],
      "metadata": {
        "id": "yXvOsrLaWU9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "id": "35DJmNiHWcYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc8dd993-5dc1-4af3-e188-c5fe875444ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from difflib import SequenceMatcher  # For fuzzy matching\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "RPBix9JnWYnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading of data from excel(company details )\n",
        "and resume(user side)"
      ],
      "metadata": {
        "id": "XexYGl6vWgny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "36wtislqWrKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675b6e54-9b5c-4c48-ec4f-eda4b7c71c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "excel_file = '/content/drive/MyDrive/internship_data.xlsx'\n",
        "df = pd.read_excel(excel_file)\n",
        "print(\"Column Names:\", df.columns)\n",
        "skills_column = df['Skills_Required']\n",
        "print(skills_column)"
      ],
      "metadata": {
        "id": "mD7ZyZnvWuxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4926c86-d3e2-4715-f320-21f0455c021e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names: Index(['Sno', 'Profile', 'Company', 'Location', 'Start Date', 'Duration',\n",
            "       'Stipend', 'Unnamed: 7', 'Apply By', 'About Internship',\n",
            "       'Skills_Required', 'Who Can Apply', 'About Company'],\n",
            "      dtype='object')\n",
            "0       ['Business Analysis', 'Business Research', 'Ef...\n",
            "1       ['Advanced Excel', 'Facebook Ads', 'Google Ana...\n",
            "2        ['Effective Communication', 'MS-Excel', 'Sales']\n",
            "3       ['Certificate', 'Letter of recommendation', 'F...\n",
            "4       ['Adobe XD', 'Figma', 'PROTOTYPING', 'Sketch',...\n",
            "                              ...                        \n",
            "1629    ['Adobe After Effects', 'Adobe Creative Suite'...\n",
            "1630    ['Creative Writing', 'Digital Marketing', 'Fac...\n",
            "1631    ['Effective Communication', 'English Proficien...\n",
            "1632    ['Effective Communication', 'English Proficien...\n",
            "1633    ['Effective Communication', 'English Proficien...\n",
            "Name: Skills_Required, Length: 1634, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "excel_file = '/content/drive/MyDrive/internship_data.xlsx'\n",
        "df = pd.read_excel(excel_file)"
      ],
      "metadata": {
        "id": "Pcs31ZmiWnej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraction and cleaning of data using pdfplumber\n",
        "\n",
        "extraction of data is done by checking \"Skills\" section in the resume then next text after the word\"\"skills\" is taken as skills , garbage of the skills extration is done by if words is not seperated by comma or continous text is used wioth out gap is recongised as garbage , since all of the resume skills section either has a comma seperated value or set space seperated value in it ."
      ],
      "metadata": {
        "id": "WEgc5XX4Wypf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "skills_column = df['Skills_Required']\n",
        "unique_skills = set()\n",
        "\n",
        "for skills in skills_column:\n",
        "    skill_list = str(skills).split(',')\n",
        "    for skill in skill_list:\n",
        "        clean_skill = re.sub(r'[{}[\\]\"\\']', '', skill).strip().lower()\n",
        "        if len(clean_skill) > 1 and not clean_skill.isdigit():\n",
        "            unique_skills.add(clean_skill)\n",
        "\n",
        "final_skill_list = sorted(unique_skills)\n"
      ],
      "metadata": {
        "id": "eP_0fdvCXou-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_skills(text):\n",
        "    raw_skills = text.split(',')\n",
        "    cleaned_skills = [skill.strip().lower() for skill in raw_skills if len(skill.strip().split()) <= 2]\n",
        "    return cleaned_skills\n"
      ],
      "metadata": {
        "id": "beGADOuVXpaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example skills extracted from resume (replace with actual extraction logic)\n",
        "import pdfplumber\n",
        "with pdfplumber.open('/content/drive/MyDrive/resume/resume/10089434.pdf') as pdf:\n",
        "    for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        skills_index = text.find('Skills')\n",
        "\n",
        "        if skills_index != -1:\n",
        "            skills_section = text[skills_index:skills_index + int(len(text) * 0.25)]\n",
        "            break\n",
        "skills_list = extract_skills(skills_section)\n",
        "\n",
        "excel_skills = [skill.lower().strip() for skill in final_skill_list]\n",
        "resume_skills = [skill.lower().strip() for skill in skills_list]"
      ],
      "metadata": {
        "id": "q_LcQbPVXslU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skill matching with the \"fuzzy matching\" logic .\n",
        "fuzzy logic is an approach to variable processing that allows for multiple possibl truth values to be processed throgh the same varibale."
      ],
      "metadata": {
        "id": "2h0GCiguX2Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fuzzy matching function (for skill matching)\n",
        "def fuzzy_match(skill, skills_required):\n",
        "\n",
        "    return SequenceMatcher(None, skill, skills_required).ratio()\n",
        "\n",
        "def convert_stipend(stipend):\n",
        "    stipend = stipend.replace('₹', '').strip().lower()\n",
        "\n",
        "    if 'unpaid' in stipend:\n",
        "        return 0.0\n",
        "\n",
        "    stipend = stipend.replace(',', '')\n",
        "\n",
        "    if '/week' in stipend:\n",
        "        weekly_value = stipend.replace('/week', '').strip()\n",
        "        try:\n",
        "            weekly_value = float(re.sub(r'[^\\d.]', '', weekly_value))\n",
        "            return weekly_value * 4\n",
        "        except ValueError:\n",
        "            return 0.0\n",
        "\n",
        "    stipend = stipend.replace('/month', '').strip()\n",
        "    if '-' in stipend:\n",
        "        try:\n",
        "            low, high = stipend.split('-')\n",
        "            return (float(low.strip()) + float(high.strip())) / 2\n",
        "        except ValueError:\n",
        "            return 0.0\n",
        "\n",
        "    try:\n",
        "        return float(stipend)\n",
        "    except ValueError:\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "kmWycgGhYS7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping the taken set of skills with the resume and mapping eith the company skills using fuzzy matching logic"
      ],
      "metadata": {
        "id": "f5YgUOHiYgws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matching logic: Map resume skills to the companies that require them using fuzzy matching\n",
        "company_count = {}\n",
        "for skill in resume_skills:\n",
        "    for index, row in df.iterrows():\n",
        "        if isinstance(row['Skills_Required'], str):\n",
        "            skills_required = row['Skills_Required'].lower()\n",
        "            if any(fuzzy_match(skill, req_skill) > 0.7 for req_skill in skills_required.split(',')):  # Fuzzy matching\n",
        "                company = row['Company']\n",
        "                if company not in company_count:\n",
        "                    company_count[company] = {'matches': 0, 'stipend': 0.0}\n",
        "                company_count[company]['matches'] += 1"
      ],
      "metadata": {
        "id": "9VgZ3mumYgF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "excess information and sorting with not only the highest matched skills but also with the amount of stipend given to the intern joinee by method of hybrid (90 percent ) and normalized (10 percent)"
      ],
      "metadata": {
        "id": "lz0zjMmjYvN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add stipend information and normalize for each company\n",
        "max_stipend = 0\n",
        "for company in company_count:\n",
        "    stipend_value = df[df['Company'] == company]['Stipend'].values[0]\n",
        "    stipend_value = convert_stipend(stipend_value)\n",
        "    company_count[company]['stipend'] = stipend_value\n",
        "    max_stipend = max(max_stipend, stipend_value)"
      ],
      "metadata": {
        "id": "1U-ftVPNYqZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid scoring: 90% skill match, 10% normalized stipend\n",
        "recommendations = []\n",
        "for company, values in company_count.items():\n",
        "    skill_match_score = values['matches'] * 0.9\n",
        "    stipend_score = (values['stipend'] / max_stipend) * 0.1 if max_stipend > 0 else 0\n",
        "    total_score = skill_match_score + stipend_score\n",
        "\n",
        "    company_details = df[df['Company'] == company].iloc[0]\n",
        "    recommendations.append({\n",
        "        'Company': company,\n",
        "        'Profile': company_details['Profile'],\n",
        "        'Location': company_details['Location'],\n",
        "        'Stipend': company_details['Stipend'],\n",
        "        'Matched Skills': values['matches'],\n",
        "        'Total Score': total_score\n",
        "    })"
      ],
      "metadata": {
        "id": "zRGvqxxYZboc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting of the filtered comapny list in order of hybrid (90 % of skill matching )and standard (10% stipend matching)  "
      ],
      "metadata": {
        "id": "cQKxRXxhZf8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "recommendations = sorted(recommendations, key=lambda x: x['Total Score'], reverse=True)\n",
        "\n",
        "# Display the top 10 recommended internship companies\n",
        "print(\"\\nRecommended Internship Companies:\")\n",
        "for i, rec in enumerate(recommendations[:10], 1):\n",
        "    print(f\"Company {i}: {rec['Company']}, Profile: {rec['Profile']}, Location: {rec['Location']}, \"\n",
        "          f\"Stipend: {rec['Stipend']}, Matched Skills: {rec['Matched Skills']}, Total Score: {rec['Total Score']:.2f}\")"
      ],
      "metadata": {
        "id": "66hZ29OvZcX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c78b16f-cae2-46e9-cebc-fceb74c3148f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommended Internship Companies:\n",
            "Company 1: Pawzz Foundation, Profile: Youth Empowerment, Location: Work from home, Stipend: ₹ 1,500-10,000 /month, Matched Skills: 3, Total Score: 2.73\n",
            "Company 2: Samridh Harshit, Profile: Full Stack Development, Location: Work from home, Stipend: ₹ 1,500 /month +  Incentives, Matched Skills: 2, Total Score: 1.81\n",
            "Company 3: The Super Focus Club, Profile: Software Development, Location: Work from home, Stipend: ₹ 15,000-25,000 /month, Matched Skills: 1, Total Score: 1.00\n",
            "Company 4: AIMonk Labs Technology Limited, Profile: Deep Learning, Location: Work from home, Stipend: ₹ 15,000-25,000 /month, Matched Skills: 1, Total Score: 1.00\n",
            "Company 5: Bilateral Solutions Private Limited, Profile: Digital Marketing (Work From Office), Location: Mandi, Stipend: ₹ 20,000 /month, Matched Skills: 1, Total Score: 1.00\n",
            "Company 6: Dalisoft Technologies Private Limited, Profile: Software Development, Location: Gurgaon, Stipend: ₹ 15,000-25,000 /month, Matched Skills: 1, Total Score: 1.00\n",
            "Company 7: K12 Techno Service Private Limited (Orchids International School), Profile: Video Editing/Making (Bangalore), Location: Bangalore, Stipend: ₹ 12,150 /month, Matched Skills: 1, Total Score: 0.96\n",
            "Company 8: Snapmydesign, Profile: Front End Development, Location: Bangalore, Stipend: ₹ 8,000-15,000 /month, Matched Skills: 1, Total Score: 0.96\n",
            "Company 9: Entrayn Education Technologies Private Limited, Profile: WordPress Development, Location: Chennai, Stipend: ₹ 7,500-15,000 /month, Matched Skills: 1, Total Score: 0.96\n",
            "Company 10: Latracal Solutions Private Limited, Profile: Full Stack Development, Location: Bangalore, Stipend: ₹ 11,000 /month, Matched Skills: 1, Total Score: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing of the final list to the excel sheet"
      ],
      "metadata": {
        "id": "KZOJXf7bZ40J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save recommendations to Excel\n",
        "recommended_df = pd.DataFrame(recommendations)\n",
        "recommended_df.to_excel('/content/drive/MyDrive/recommended_internships_fuzzy_hybrid.xlsx', index=False)"
      ],
      "metadata": {
        "id": "Gge_Er2daAN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ML model approach using vectorization **"
      ],
      "metadata": {
        "id": "dzzrbx3l_ieo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "excel_file = '/content/drive/MyDrive/internship_data.xlsx'\n",
        "df = pd.read_excel(excel_file)"
      ],
      "metadata": {
        "id": "SLIM3FGc_U9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract skills required by companies and clean up"
      ],
      "metadata": {
        "id": "ZoptmnGt_9Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['Skills Required'] = df['Skills_Required'].str.lower().str.replace(r'[{}[\\]\"\\']', '', regex=True)\n",
        "\n",
        "skills_section = resume_skills"
      ],
      "metadata": {
        "id": "gk2m2fn5_rJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a TF-IDF Vectorizer\n",
        "Fit the model on the 'Skills Required' and transform into TF-IDF matrix\n",
        "generalize the skills\n",
        "Calculate cosine similarity between the resume and the internship skills\n",
        "add similarity score to dataframe"
      ],
      "metadata": {
        "id": "cyJSFYE6AEKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['Skills Required'])\n",
        "\n",
        "# Transform the resume skills into TF-IDF\n",
        "\n",
        "resume_tfidf = tfidf_vectorizer.transform([' '.join(skills_section).lower()])\n",
        "\n",
        "cosine_similarities = cosine_similarity(resume_tfidf, tfidf_matrix)\n",
        "\n",
        "df['Similarity Score'] = cosine_similarities.flatten()"
      ],
      "metadata": {
        "id": "EIZQcDCy_r0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort the DataFrame based on similarity score and get the top 10 recommendations\n"
      ],
      "metadata": {
        "id": "tDQ-GBGKAfi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "recommended_internships = df.sort_values(by='Similarity Score', ascending=False).head(10)\n",
        "\n",
        "print(\"\\nRecommended Internship Companies:\")\n",
        "for index, row in recommended_internships.iterrows():\n",
        "    print(f\"Company: {row['Company']}, Profile: {row['Profile']}, Location: {row['Location']}, \"\n",
        "          f\"Stipend: {row['Stipend']}, Similarity Score: {row['Similarity Score']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWbydrJp_1zh",
        "outputId": "11abee84-9442-4ed2-e4f8-8b52a4083976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommended Internship Companies:\n",
            "Company: Requin Solutions Private Limited, Profile: Subject Matter Expert (Civil Engineering), Location: Jaipur, Stipend: ₹ 10,000 /month, Similarity Score: 0.3679\n",
            "Company: Hamari Pahchan NGO, Profile: General Management, Location: Delhi, South, Stipend: ₹ 3,000-5,000 /month, Similarity Score: 0.3667\n",
            "Company: Dalisoft Technologies Private Limited, Profile: Software Development, Location: Gurgaon, Stipend: ₹ 15,000-25,000 /month, Similarity Score: 0.3653\n",
            "Company: Doodhvale, Profile: Business Strategy, Location: Delhi, Stipend: ₹ 7,000 /month, Similarity Score: 0.3186\n",
            "Company: Robokart, Profile: Electrical Engineering, Location: Ahmedabad, Bhavnagar, Gandhinagar, Mehsana, Surat, Anand, Navsari, Vadodara, Dahod, Bharuch, Sabarkatha, Panchmahal, Banaskantha, Mahisagar, Narmada, Stipend: ₹ 5,000 /month, Similarity Score: 0.3139\n",
            "Company: Senso Vision System, Profile: SAS Marketing Intern, Location: Bangalore, Stipend: ₹ 8,000 /month, Similarity Score: 0.2615\n",
            "Company: Rentkar-Switch To Share, Profile: Accounts, Location: Mumbai, Stipend: ₹ 12,000-16,000 /month, Similarity Score: 0.2578\n",
            "Company: Enseur, Profile: 3D Designer, Location: Delhi, Stipend: ₹ 3,000-10,000 /month, Similarity Score: 0.2045\n",
            "Company: K12 Techno Service Private Limited (Orchids International School), Profile: Coding Teacher Jodhpur, Location: Jodhpur, Stipend: ₹ 15,000-25,000 /month, Similarity Score: 0.1908\n",
            "Company: Jarurat Care, Profile: Backend Web Developer, Location: Work from home, Stipend: Unpaid, Similarity Score: 0.1605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optionally, save recommendations to a new Excel file"
      ],
      "metadata": {
        "id": "mIvVO73yAkaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_internships.to_excel('/content/drive/MyDrive/recommended_internships_ml.xlsx', index=False)"
      ],
      "metadata": {
        "id": "NXliDikz_2ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "recommended_internship = recommended_internships\n",
        "\n",
        "similarity_threshold = 0.2\n",
        "recommended_internships['Similarity Score'] = pd.to_numeric(recommended_internships['Similarity Score'])\n",
        "relevant_retrieved = sum(1 for _, internship in recommended_internships.iterrows() if internship['Similarity Score'] > similarity_threshold)\n",
        "total_retrieved = len(recommended_internships)\n",
        "\n",
        "total_actual_relevant = relevant_retrieved\n",
        "\n",
        "\n",
        "precision = relevant_retrieved / total_retrieved if total_retrieved != 0 else 0\n",
        "recall = relevant_retrieved / total_actual_relevant if total_actual_relevant != 0 else 0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "print(f'Estimated Precision: {precision:.2f}')\n",
        "print(f'Estimated Recall: {recall:.2f}')\n",
        "print(f'Estimated F1 Score: {f1_score:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Vc9DESRy6s",
        "outputId": "0754054c-9f12-4c0b-c565-5eb1e3830951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated Precision: 0.80\n",
            "Estimated Recall: 1.00\n",
            "Estimated F1 Score: 0.89\n"
          ]
        }
      ]
    }
  ]
}